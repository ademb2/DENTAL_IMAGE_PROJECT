{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56382/2533136695.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_weights_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class index: 0\n",
      "Predicted label: AI_cohort\n",
      "Probabilities: tensor([[9.9980e-01, 2.2191e-08, 1.9826e-04]])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Define paths directly\n",
    "IMAGE_PATH = '../data/test/AI.jpeg'  # Specify the full path to your image\n",
    "MODEL_PATH = '../VGG16_img224x224_batch32_epochs40_lr0.00010.pth'  # Specify the full path to your model weights\n",
    "LABELS_JSON_PATH = '../outputs/models/best/label_mapping.json'  # Specify the full path to your labels JSON\n",
    "\n",
    "# Fixed number of classes\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "def create_transforms(image_size):\n",
    "    \"\"\"Create and return transformations for the input image.\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(height=image_size[0], width=image_size[1]),\n",
    "        A.Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def load_labels(json_path):\n",
    "    \"\"\"Load class labels from a JSON file.\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        return json.load(f)['labels']\n",
    "\n",
    "def load_image(image_path, transforms):\n",
    "    \"\"\"Load and preprocess the image for VGG16 using Albumentations.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = np.array(image)  # Convert to numpy array for Albumentations\n",
    "    transformed_image = transforms(image=image)['image']  # Apply transformations\n",
    "    return transformed_image.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "def get_vgg16_model(model_weights_path):\n",
    "    \"\"\"Initialize and return the VGG16 model with specified weights.\"\"\"\n",
    "    model = models.vgg16(weights=None)  # Set weights=None to prevent downloading\n",
    "    model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, NUM_CLASSES)\n",
    "\n",
    "    # Load your custom weights\n",
    "    state_dict = torch.load(model_weights_path, map_location='cpu')\n",
    "\n",
    "    # Remove 'module.' prefix if it exists\n",
    "    if 'module.' in next(iter(state_dict.keys())):\n",
    "        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(image_path, labels_json_path):\n",
    "    \"\"\"Load image, model, and make predictions.\"\"\"\n",
    "    labels = load_labels(labels_json_path)\n",
    "    \n",
    "    # Create transforms with the desired image size (224x224 for VGG16)\n",
    "    transforms = create_transforms(image_size=(224, 224))\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    image = load_image(image_path, transforms)\n",
    "\n",
    "    model = get_vgg16_model(MODEL_PATH)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(image)  # Raw predictions\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)  # Convert to probabilities\n",
    "        predicted_class_index = torch.argmax(probabilities, dim=1).item()  # Get the predicted class index\n",
    "\n",
    "    predicted_label = labels[str(predicted_class_index)]\n",
    "    return predicted_label, predicted_class_index, probabilities\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predicted_label, predicted_class_index, probabilities = predict(IMAGE_PATH, LABELS_JSON_PATH)\n",
    "\n",
    "    print(\"Predicted class index:\", predicted_class_index)\n",
    "    print(\"Predicted label:\", predicted_label)\n",
    "    print(\"Probabilities:\", probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8485/561143928.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_weights_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class index: 0\n",
      "Predicted label: AI_cohort\n",
      "Probabilities: tensor([[9.9929e-01, 1.6859e-05, 6.9129e-04]])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Define paths directly\n",
    "IMAGE_PATH = '../data/test/PXL_20241025_201012979.jpg'  # Specify the full path to your image\n",
    "MODEL_PATH = '../outputs/models/best/_epoch34_best.pth'  # Specify the full path to your model weights\n",
    "LABELS_JSON_PATH = '../outputs/models/best/label_mapping.json'  # Specify the full path to your labels JSON\n",
    "\n",
    "# Fixed number of classes\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "def create_transforms(image_size):\n",
    "    \"\"\"Create and return transformations for the input image.\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(height=image_size[0], width=image_size[1]),\n",
    "        A.Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def load_labels(json_path):\n",
    "    \"\"\"Load class labels from a JSON file.\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        return json.load(f)['labels']\n",
    "\n",
    "def load_image(image_path, transforms):\n",
    "    \"\"\"Load and preprocess the image for VGG16 using Albumentations.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = np.array(image)  # Convert to numpy array for Albumentations\n",
    "    transformed_image = transforms(image=image)['image']  # Apply transformations\n",
    "    return transformed_image.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "def get_vgg16_model(model_weights_path):\n",
    "    \"\"\"Initialize and return the VGG16 model with specified weights.\"\"\"\n",
    "    model = models.vgg16(weights=None)  # Set weights=None to prevent downloading\n",
    "    model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, NUM_CLASSES)\n",
    "\n",
    "    # Load your custom weights\n",
    "    checkpoint = torch.load(model_weights_path, map_location='cpu')\n",
    "    state_dict = checkpoint['model_state_dict']  # Extract model state dict from checkpoint\n",
    "\n",
    "    # Remove 'module.' prefix if it exists\n",
    "    if 'module.' in next(iter(state_dict.keys())):\n",
    "        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(image_path, labels_json_path):\n",
    "    \"\"\"Load image, model, and make predictions.\"\"\"\n",
    "    labels = load_labels(labels_json_path)\n",
    "    \n",
    "    # Create transforms with the desired image size (224x224 for VGG16)\n",
    "    transforms = create_transforms(image_size=(224, 224))\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    image = load_image(image_path, transforms)\n",
    "\n",
    "    model = get_vgg16_model(MODEL_PATH)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(image)  # Raw predictions\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)  # Convert to probabilities\n",
    "        predicted_class_index = torch.argmax(probabilities, dim=1).item()  # Get the predicted class index\n",
    "\n",
    "    predicted_label = labels[str(predicted_class_index)]\n",
    "    return predicted_label, predicted_class_index, probabilities\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predicted_label, predicted_class_index, probabilities = predict(IMAGE_PATH, LABELS_JSON_PATH)\n",
    "\n",
    "    print(\"Predicted class index:\", predicted_class_index)\n",
    "    print(\"Predicted label:\", predicted_label)\n",
    "    print(\"Probabilities:\", probabilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next\n",
    "get model weights only from \n",
    "optimize speed \n",
    "qunatize model\n",
    "deploy model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
